{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dogs_vs_cats-v-1-0-9.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cubecloud/dogs_vs_cats/blob/master/dogs_vs_cats_v_1_0_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAl-JTvzvbHC",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qJfJPd0PrzT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%tensorflow_version 2.x\n",
        "%tensorflow_version 1.15.2\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NJL_gODxWhp",
        "colab_type": "code",
        "outputId": "e5d77c3a-5d8d-45fe-9625-e17629dfb6d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "#%tensorflow_version 2.x\n",
        "%tensorflow_version 1.15.2\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.15.2`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n",
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TTUHDm3P7oZ",
        "colab_type": "code",
        "outputId": "8a32bc91-e507-4578-ab5b-8def91fa65b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7D-uEuguvcgl",
        "colab_type": "code",
        "outputId": "30af69bb-298d-4031-fe78-a58bce4e8330",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "#%tensorflow_version 2.x\n",
        "%tensorflow_version 1.15.2\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "import os\n",
        "import glob\n",
        "import pytz\n",
        "import datetime\n",
        "from math import exp\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import models\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.15.2`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FR_nxwysvW3p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "version=109\n",
        "timezone = pytz.timezone(\"Europe/Moscow\")\n",
        "image_size = 150\n",
        "batch_size = 40\n",
        "epochs = 150\n",
        "start_learning_rate = 0.001\n",
        "start_patience = round(epochs*0.04)\n",
        "\n",
        "print (f'Image Size = {image_size}x{image_size}')\n",
        "\n",
        "def make_model(input_shape, num_classes):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    # Image augmentation block\n",
        "    # x = data_augmentation(inputs)\n",
        "    x = inputs\n",
        "    # Entry block\n",
        "    # x = layers.experimental.preprocessing.Rescaling(1.0 / 255)(x)\n",
        "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization( momentum=0.9 )(x) # added momentum [ 0.9 ]\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = layers.Dropout(0.5)(x) #<= added dropout layer [ ]\n",
        "\n",
        "    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization( momentum=0.9 )(x) # added momentum [ 0.9 ]\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    previous_block_activation = x  # Set aside residual\n",
        "\n",
        "    for size in [128, 256, 512, 728]:\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization( momentum=0.9)(x) # added momentum [ 0.9 ]\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        \n",
        "        # x = layers.Dropout(0.5)(x) #<= added dropout layer [ ]\n",
        "        \n",
        "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization( momentum=0.9 )(x) # added momentum [ 0.9 ]\n",
        "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
        "            previous_block_activation\n",
        "        )\n",
        "        x = layers.add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization( momentum=0.9 )(x) # added momentum [ 0.9 ]\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = layers.Dropout(0.5)(x) #<= added dropout layer [ 0.2 0.5 ]\n",
        "    \n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    if num_classes == 2:\n",
        "        activation = \"sigmoid\"\n",
        "        units = 1\n",
        "    else:\n",
        "        activation = \"softmax\"\n",
        "        units = num_classes\n",
        "\n",
        "    x = layers.Dropout(0.6)(x) #<= dropout [ 0.5, 0.52, 0.5, 0.6 ,0.6 ]\n",
        "    outputs = layers.Dense(units, activation=activation)(x)\n",
        "    return keras.Model(inputs, outputs)\n",
        "\n",
        "home_dir = \"/content/drive/My Drive/Colab Notebooks/dogs_vs_cats/\"\n",
        "base_dir = \"/content/drive/My Drive/Colab Notebooks/dogs_vs_cats/data/\"\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "# data loading\n",
        "# ----------------------------------------------------\n",
        "\n",
        "x_train = np.load(os.path.join(home_dir, 'dogs_vs_cats_photos_train.npy'))\n",
        "y_train = np.load(os.path.join(home_dir,'dogs_vs_cats_labels_train.npy'))[2:,]\n",
        "x_validation = np.load(os.path.join(home_dir,'dogs_vs_cats_photos_validation.npy'))\n",
        "y_validation = np.load(os.path.join(home_dir,'dogs_vs_cats_labels_validation.npy'))[2:,]\n",
        "print (x_train.shape, y_train.shape)\n",
        "print (x_validation.shape, y_validation.shape)\n",
        "# ----------------------------------------------------\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30, # <= [ 40, 30 ]\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False,\n",
        "    fill_mode=\"nearest\")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_datagen.fit(x_train)\n",
        "\n",
        "train_generator = train_datagen.flow(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size)\n",
        "\n",
        "validation_generator = validation_datagen.flow(\n",
        "    x=x_validation,\n",
        "    y=y_validation,\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size)\n",
        "\n",
        "model = make_model(input_shape=(image_size,image_size) + (3,), num_classes=2)\n",
        "keras.utils.plot_model(model, show_shapes=True)\n",
        "model.summary()\n",
        "\n",
        "def scheduler(epoch):\n",
        "  if epoch < 10:\n",
        "    return start_learning_rate\n",
        "  else:\n",
        "    # return start_learning_rate * exp(0.1 * (10 - epoch))\n",
        "    return start_learning_rate*(0.75**(epoch//10))\n",
        "\n",
        "class EarlyStoppingAtMinValLoss(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, start_learning_rate=start_learning_rate, patience=3):\n",
        "    super(EarlyStoppingAtMinValLoss, self).__init__()\n",
        "    self.patience = patience\n",
        "    self.start_learning_rate = start_learning_rate\n",
        "    # best_weights to store the weights at which the minimum loss occurs.\n",
        "    self.best_weights = None\n",
        "\n",
        "  def on_train_begin(self, logs=None):\n",
        "    # The number of epoch it has waited when loss is no longer minimum.\n",
        "    self.wait = 0\n",
        "    # The epoch the training stops at.\n",
        "    self.stopped_epoch = 0\n",
        "    # Initialize the best as infinity.\n",
        "    self.best = np.Inf\n",
        "  \n",
        "  def on_epoch_begin(self, epoch, logs=None):\n",
        "    if (epoch >= 10) and (epoch%10 == 0):\n",
        "      self.patience += round((epochs-epoch)*0.03)\n",
        "    # self.patience = round((self.start_learning_rate / scheduler (epoch) + (epochs*0.15))/2)\n",
        "    print (f'Patience: {self.patience}')\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    current = logs.get('val_loss')\n",
        "    if np.less(current, self.best):\n",
        "      self.best = current\n",
        "      self.wait = 0\n",
        "      # Record the best weights if current results is better (less).\n",
        "      self.best_weights = self.model.get_weights()\n",
        "    else:\n",
        "      self.wait += 1\n",
        "      if self.wait >= self.patience:\n",
        "        self.stopped_epoch = epoch\n",
        "        self.model.stop_training = True\n",
        "        print('Restoring model weights from the end of the best epoch.')\n",
        "        self.model.set_weights(self.best_weights)\n",
        "\n",
        "  def on_train_end(self, logs=None):\n",
        "    if self.stopped_epoch > 0:\n",
        "      print('Epoch %05d: early stopping' % (self.stopped_epoch + 1))\n",
        "\n",
        "  # def on_train_batch_begin(self, batch, logs=None):\n",
        "  #   print('Training: batch {} begins at {}'.format(batch, datetime.datetime.now(timezone).time()))\n",
        "\n",
        "\n",
        "lrs = keras.callbacks.LearningRateScheduler(scheduler, verbose=1)\n",
        "log_dir = os.path.join(home_dir, 'logs/fit')\n",
        "esmvl = EarlyStoppingAtMinValLoss (patience=start_patience)\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', patience=start_patience, verbose=1)\n",
        "tb = TensorBoard(log_dir=log_dir, histogram_freq=10, write_graph=True, write_images=False )\n",
        "\n",
        "def filename_with_time (prefix_str, root_str):\n",
        "  return prefix_str + root_str + str(datetime.datetime.now(timezone).strftime(\"%d-%m-%Y_%H-%M\"))\n",
        "\n",
        "model_name= f'cats_and_dogs_{str(version)}_{str(image_size)}x{str(image_size)}_{str(batch_size)}_'\n",
        "chkp = keras.callbacks.ModelCheckpoint(os.path.join(home_dir,'save/', filename_with_time(model_name,\"save_at_{epoch:02d}-{val_loss:.4f}_\") + \".h5\"), monitor='val_loss', save_best_only=True)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(lr=start_learning_rate),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "callbacks = [lrs,  esmvl, chkp ]\n",
        "\n",
        "start = datetime.datetime.now()\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch = len(train_generator),\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps = len(validation_generator),\n",
        "    epochs = epochs,\n",
        "    verbose=1,\n",
        "    callbacks = callbacks)\n",
        "\n",
        "end = datetime.datetime.now()\n",
        "print (f'Planned epochs: {epochs} Calculated epochs : {len(history.history[\"loss\"])} Time elapsed: {end - start}')\n",
        "epochs = len(history.history['loss'])\n",
        "model_name= f'cats_and_dogs_{str(version)}_{str(image_size)}x{str(image_size)}_{str(batch_size)}_epochs-{epochs}_'\n",
        "model.save(os.path.join(home_dir, model_name + str(datetime.datetime.now(timezone).strftime(\"%d-%m-%Y_%H-%M\")) + '.h5'))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize=(15,12))\n",
        "gs = fig.add_gridspec(1, 1)\n",
        "ax1 = fig.add_subplot()\n",
        "# Don't allow the axis to be on top of your data\n",
        "ax1.set_axisbelow(True)\n",
        "# Turn on the minor TICKS, which are required for the minor GRID\n",
        "ax1.minorticks_on()\n",
        "# Customize the major grid\n",
        "ax1.grid(which='major', linestyle='-', linewidth='0.5', color='gray')\n",
        "# Customize the minor grid\n",
        "ax1.grid(which='minor', linestyle=':', linewidth='0.5', color='gray')\n",
        "N = np.arange(0, len(history.history[\"acc\"]) )\n",
        "plt.plot(N, history.history[\"loss\"], linestyle='-', color='red', label=\"Training loss\")\n",
        "plt.plot(N, history.history[\"acc\"], linestyle='-.', color='magenta', label=\"Training accuracy\")\n",
        "plt.plot(N, history.history[\"val_loss\"], linestyle='--', color='blue', label=\"Validation loss\")\n",
        "plt.plot(N, history.history[\"val_acc\"], linestyle=':', color='violet', label=\"Validation accuracy\")\n",
        "plt.title(\"Training/validation Loss and Accuracy\")\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(home_dir,'figures', ('fig_' + model_name + str(datetime.datetime.now(timezone).strftime(\"%d-%m-%Y_%H-%M\"))+'.png')))\n",
        "plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRQtvuF2AF21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_filenames = os.listdir(\"../input/test1/test1\")\n",
        "test_df = pd.DataFrame({\n",
        "    'filename': test_filenames\n",
        "})\n",
        "nb_samples = test_df.shape[0]\n",
        "test_gen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_gen.flow_from_dataframe(\n",
        "    test_df, \n",
        "    \"../input/test1/test1/\", \n",
        "    x_col='filename',\n",
        "    y_col=None,\n",
        "    class_mode=None,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")\n",
        "predict = model.predict_generator(test_generator, steps=np.ceil(nb_samples/batch_size))\n",
        "test_df['category'] = np.argmax(predict, axis=-1)\n",
        "label_map = dict((v,k) for k,v in train_generator.class_indices.items())\n",
        "test_df['category'] = test_df['category'].replace(label_map)\n",
        "test_df['category'] = test_df['category'].replace({ 'dog': 1, 'cat': 0 })\n",
        "\n",
        "\n",
        "sample_test = test_df.head(18)\n",
        "sample_test.head()\n",
        "plt.figure(figsize=(12, 24))\n",
        "for index, row in sample_test.iterrows():\n",
        "    filename = row['filename']\n",
        "    category = row['category']\n",
        "    img = load_img(\"../input/test1/test1/\"+filename, target_size=IMAGE_SIZE)\n",
        "    plt.subplot(6, 3, index+1)\n",
        "    plt.imshow(img)\n",
        "    plt.xlabel(filename + '(' + \"{}\".format(category) + ')' )\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKuWZeFY5Nq1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir='log_dir'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7li9n2D0HO3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/fit "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4Qb_0xevhSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize=(15,12))\n",
        "gs = fig.add_gridspec(1, 1)\n",
        "ax1 = fig.add_subplot()\n",
        "# Don't allow the axis to be on top of your data\n",
        "ax1.set_axisbelow(True)\n",
        "# Turn on the minor TICKS, which are required for the minor GRID\n",
        "ax1.minorticks_on()\n",
        "# Customize the major grid\n",
        "ax1.grid(which='major', linestyle='-', linewidth='0.5', color='gray')\n",
        "# Customize the minor grid\n",
        "ax1.grid(which='minor', linestyle=':', linewidth='0.5', color='gray')\n",
        "N = np.arange(0, len(history.history[\"acc\"]) )\n",
        "plt.plot(N, history.history[\"loss\"], linestyle='-', color='red', label=\"Training loss\")\n",
        "plt.plot(N, history.history[\"acc\"], linestyle='-.', color='magenta', label=\"Training accuracy\")\n",
        "plt.plot(N, history.history[\"val_loss\"], linestyle='--', color='blue', label=\"Validation loss\")\n",
        "plt.plot(N, history.history[\"val_acc\"], linestyle=':', color='violet', label=\"Validation accuracy\")\n",
        "plt.title(\"Training/validation Loss and Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig(os.path.join(home_dir,'figures', ('fig_' + model_name + str(datetime.datetime.now(timezone).strftime(\"%d-%m-%Y_%H-%M\"))+'.png')))\n",
        "plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UP4OUNWCUuhA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensorboard --inspect --logdir='log_dir'"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}